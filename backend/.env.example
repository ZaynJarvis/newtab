# =============================================================================
# New Tab Backend Configuration
# Copy this file to .env and fill in your actual values
# =============================================================================

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Provider options: openai, claude, groq, ark
LLM_PROVIDER=openai
EMBEDDING_PROVIDER=openai

# API Token Configuration
# - API_TOKEN: Default token used for both LLM and embedding providers
# - LLM_API_TOKEN: Specific token for LLM provider (optional, overrides API_TOKEN)
# - EMBEDDING_API_TOKEN: Specific token for embedding provider (optional, overrides API_TOKEN)
API_TOKEN=your-api-token-here
# LLM_API_TOKEN=your-llm-specific-token
# EMBEDDING_API_TOKEN=your-embedding-specific-token

# Optional: Custom endpoints (overrides provider defaults)
# LLM_ENDPOINT=https://your-custom-llm-endpoint.com/v1/chat/completions
# EMBEDDING_ENDPOINT=https://your-custom-embedding-endpoint.com/v1/embeddings

# Optional: Custom models (overrides provider defaults)
# LLM_MODEL=your-preferred-llm-model
# EMBEDDING_MODEL=your-preferred-embedding-model

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info
RELOAD=true

# =============================================================================
# DATABASE & STORAGE CONFIGURATION
# =============================================================================
DATABASE_FILE=/app/data/web_memory.db
QUERY_CACHE_FILE=/app/data/query_embeddings_cache.json

# =============================================================================
# VECTOR CONFIGURATION
# =============================================================================
VECTOR_DIMENSION=2048
MAX_VECTORS=10000

# =============================================================================
# API PERFORMANCE TUNING
# =============================================================================
MAX_RETRIES=3
RETRY_DELAY=1.0
REQUEST_TIMEOUT=30.0
HEALTH_CHECK_TIMEOUT=5.0

# =============================================================================
# CACHE CONFIGURATION
# =============================================================================
QUERY_CACHE_CAPACITY=1000
QUERY_CACHE_TTL_DAYS=7

# =============================================================================
# CONFIGURATION EXAMPLES
# =============================================================================

# Example 1: Default OpenAI Setup (using single token for both)
# -------------------------------------------------------------
# LLM_PROVIDER=openai
# EMBEDDING_PROVIDER=openai
# API_TOKEN=sk-your-openai-api-key

# Example 2: Claude LLM + OpenAI Embeddings (separate tokens)
# ------------------------------------------------------------
# LLM_PROVIDER=claude
# EMBEDDING_PROVIDER=openai
# LLM_API_TOKEN=sk-ant-your-claude-api-key
# EMBEDDING_API_TOKEN=sk-your-openai-api-key

# Example 3: Groq LLM + OpenAI Embeddings (separate tokens)
# ----------------------------------------------------------
# LLM_PROVIDER=groq
# EMBEDDING_PROVIDER=openai
# LLM_API_TOKEN=gsk_your-groq-api-key
# EMBEDDING_API_TOKEN=sk-your-openai-api-key
# LLM_MODEL=llama3-70b-8192

# Example 4: ByteDance ARK (Full Setup)
# -------------------------------------
# LLM_PROVIDER=ark
# EMBEDDING_PROVIDER=ark
# API_TOKEN=your-ark-api-token
# LLM_ENDPOINT=https://ark-cn-beijing.bytedance.net/api/v3/chat/completions
# LLM_MODEL=ep-20250529215531-dfpgt
# EMBEDDING_ENDPOINT=https://ark-cn-beijing.bytedance.net/api/v3/embeddings/multimodal
# EMBEDDING_MODEL=ep-20250529220411-grkkv
# VECTOR_DIMENSION=2048

# Example 5: Mixed Token Configuration (backward compatible)
# ----------------------------------------------------------
# LLM_PROVIDER=claude
# EMBEDDING_PROVIDER=openai
# API_TOKEN=sk-your-default-token  # Used for provider without specific token
# LLM_API_TOKEN=sk-ant-your-claude-api-key  # Overrides API_TOKEN for LLM
# # embedding provider will use API_TOKEN since no EMBEDDING_API_TOKEN is set

# =============================================================================
# PROVIDER API KEY LINKS
# =============================================================================
# OpenAI: https://platform.openai.com/api-keys
# Claude (Anthropic): https://console.anthropic.com/
# Groq: https://console.groq.com/keys
# ARK (ByteDance): Your ByteDance ARK dashboard